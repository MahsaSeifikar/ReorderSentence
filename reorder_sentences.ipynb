{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contemporary-literacy",
   "metadata": {},
   "source": [
    "# Reorder Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, RobertaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "published-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approved-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = pickle.load(open(os.path.join(DATA_PATH, 'train.pkl'), 'rb'))\n",
    "# test_list = pickle.load(open(os.path.join(DATA_PATH, 'test.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "native-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "# import torch\n",
    "# from torch.nn import functional as F\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "# prompt = \"The child came home from school.\"\n",
    "# next_sentence = \"He played soccer after school.\"\n",
    "# encoding = tokenizer.encode_plus(prompt, next_sentence, return_tensors='pt')\n",
    "# outputs = model(**encoding)[0]\n",
    "# softmax = F.softmax(outputs, dim = 1)\n",
    "# print(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-purchase",
   "metadata": {},
   "source": [
    "## Data Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italic-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instance in train is 590226\n",
      "Sample of train data: \n",
      " [{'ID': 589726, 'sentences': ['James Palao, also James Florestan Palao (February 19, 1879 – January 8, 1925) was an American jazz musician.', 'Later life and career\\nPalao\\'s profession was recorded as \"musician\" in the 1900 census, but little is known of his career prior to 1907, although he did play in local bands such as the Paciﬁc Brass Band.', 'Early life\\nPalao was born in Algiers, New Orleans, Louisiana, on February 19, 1879.', 'His parents were Felix Palao and Clotile Rebecca Spriggs.', 'Jimmy had violin lessons as a child.', 'Palao married Armontine Carter in 1905.'], 'indexes': [0, 4, 1, 2, 3, 5]}]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of instance in train is {len(train_list)}\")\n",
    "# print(f\"Number of instance in test is {len(test_list)}\")\n",
    "print(f\"Sample of train data: \\n {train_list[-501:-500]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-seattle",
   "metadata": {},
   "source": [
    "## Data Prepration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "under-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(columns=[\"ID\", \"sentence_1\", \"sentence_2\", \"distance\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "c = 0\n",
    "for instance in train_list:\n",
    "#     print(instance)\n",
    "    sorted_pair = sorted(zip(instance['indexes'], instance['sentences']))\n",
    "#     print(sorted_pair)\n",
    "    for i in range(len(sorted_pair)):\n",
    "        for j in range(i+1, len(sorted_pair)): \n",
    "            train_data.loc[count] = [instance[\"ID\"],  sorted_pair[i][1].lower(), sorted_pair[j][1].lower(), (j-i-1), 1]\n",
    "            count+=1    \n",
    "            train_data.loc[count] = [instance[\"ID\"],  sorted_pair[j][1].lower(), sorted_pair[i][1].lower(), (j-i-1), 0]\n",
    "            count+=1\n",
    "#     break\n",
    "    if count >= 1000000:\n",
    "        c+=1\n",
    "        print(c)\n",
    "        train_data.to_csv(f\"preprocessed_train_data_{c}.csv\", index=False)\n",
    "        train_data = train_data.iloc[0:0]\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "persistent-command",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-enemy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-identifier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-large', do_lower_case=True)\n",
    "# Load the BERT tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-television",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-daniel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "floating-donna",
   "metadata": {},
   "source": [
    "## Fine-Tune Bert "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-requirement",
   "metadata": {},
   "source": [
    "## Predict Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-milton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
